{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.1:"
      ],
      "metadata": {
        "id": "Wm4o_QCkvEb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "with epislon 0.5, the probability of selecting greedy action in 1-0.5 = 0.5"
      ],
      "metadata": {
        "id": "8J5gDGx5I-ed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.2:"
      ],
      "metadata": {
        "id": "PnmF4GuNtXMD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A_1=1 returns R_1=-1 making 2,3,4 the greedy actions for next step. returns [-1,0,0,0]\n",
        "\n",
        "A_2=2 returns R_2= 1 making 2 the greedy action for next step. returns [-1,1,0,0]\n",
        "\n",
        "A_3=2 returns R_3=-2 making 3,4 the greedy action for next step. returns [-1,(1-2)/2,0,0]\n",
        "\n",
        "A_4=2 returns R_4=2 making 2 the greedy action for next step. returns [-1,(1-2+2)/3,0,0]\n",
        "\n",
        "A_5=3 returns R_4=0 making 2 the greedy action for next step. returns [-1,(1-2+2)/3,0,0]\n",
        "\n",
        "A_4 and A_5 are the timecases where it definitely occured. A_2 is a could be cause, the best action could be 3 and the eps_greedy might have selected 2"
      ],
      "metadata": {
        "id": "1KRXlG6EJEFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.3"
      ],
      "metadata": {
        "id": "hcmp0nj40ib9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The answer is eps=0.01\n",
        "\n",
        "In the longrun, when all the true values of actions are explored, the eps-0.01 method will select the best action with a probability of 0.99 where as eps-0.1 will select the best action with a probability of 0.9"
      ],
      "metadata": {
        "id": "au2-7X7XJL6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.4\n",
        "\n",
        "Didnt get it"
      ],
      "metadata": {
        "id": "VCVQ5nZd5ryM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.5\n"
      ],
      "metadata": {
        "id": "nC2jQWv0JPis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "## Parameters ##\n",
        "k = 10\n",
        "steps = 10000\n",
        "random_walk_mean = 0\n",
        "random_walk_var = 0.01\n",
        "eps = 0.01\n",
        "alpha = 0.1\n",
        "# Create 10 distributions with mean 0 and varience 1\n",
        "mean_list = np.array([1]*k)\n",
        "varience_list = np.array([1]*k)\n",
        "\n",
        "action_value_estimates = {\n",
        "                          \"sample_averages\":np.array([0]*k),\n",
        "                          \"incremental_computation\":np.array([0]*k),\n",
        "                          \"constant_alpha\":np.array([0]*k)\n",
        "                          }\n",
        "action_counts = np.array([0]*k)\n",
        "\n",
        "avg_rew = 0\n",
        "\n",
        "for step in steps:\n",
        "\n",
        "  # Random walk means addition\n",
        "  random_walk_mean += np.random.normal(random_walk_mean, random_walk_var, size=k)"
      ],
      "metadata": {
        "id": "TlPRg82E5u2e"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.6"
      ],
      "metadata": {
        "id": "XJ_GVWglJXGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.7"
      ],
      "metadata": {
        "id": "FW6Ee3gBJfN6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.8"
      ],
      "metadata": {
        "id": "q0OUIj44JhpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.9"
      ],
      "metadata": {
        "id": "9U2O3Rn-Jj2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.10"
      ],
      "metadata": {
        "id": "Pcxb9g3xJlUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.11"
      ],
      "metadata": {
        "id": "5PHHfnUpJmpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GGrYMmD2JnyN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}